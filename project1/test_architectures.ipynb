{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unauthorized-toilet",
   "metadata": {},
   "source": [
    "# Trying different models\n",
    "\n",
    "This notebook is for creating, testing and comparing different model with different optimizations, the ones with the best results will be kept and add in the `models.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "competent-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "from dlc_practical_prologue import generate_pair_sets\n",
    "\n",
    "from modelclass import Model\n",
    "from plot import *\n",
    "\n",
    "\n",
    "\n",
    "NUMBER_ROUNDS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-broad",
   "metadata": {},
   "source": [
    "## Models definitions\n",
    "-------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "smaller-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arch1(Model):\n",
    "    \n",
    "    def __init__(self, f_gen_data, nb_epochs=25, mini_batch_size=100, learning_rate=1e-3):\n",
    "        super().__init__(f_gen_data, \"Baseline\", nb_epochs, mini_batch_size, learning_rate)\n",
    "\n",
    "        self.fc1 = nn.Linear(392, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        nb_sample = x.size()[0]\n",
    "\n",
    "        x = self.fc1(x.view(nb_sample, -1))\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "endangered-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arch2(Model):\n",
    "    \n",
    "    def __init__(self, f_gen_data, nb_epochs=25, mini_batch_size=100, learning_rate=1e-3):\n",
    "        super().__init__(f_gen_data, \"Baseline\", nb_epochs, mini_batch_size, learning_rate)\n",
    "\n",
    "        self.fc1 = nn.Linear(392, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        nb_sample = x.size()[0]\n",
    "\n",
    "        x = self.fc1(x.view(nb_sample, -1))\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "    \n",
    "    # can override parent method to use new optim\n",
    "    def _train(self, train_input, train_target, train_classes):\n",
    "        \"\"\" Train the model (method can be override by child class) \"\"\"\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), self.lr)\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        for e in range(self.epochs):\n",
    "            for b in range(0, train_input.size(0), self.batch_size):\n",
    "                output = self(train_input.narrow(0, b, self.batch_size))\n",
    "                loss = criterion(output, train_target.narrow(0, b, self.batch_size))\n",
    "                self.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                losses.append(loss.data.item())\n",
    "\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-blogger",
   "metadata": {},
   "source": [
    "## Models Training\n",
    "-------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "charitable-coordinator",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes from 2 to 5 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ab9dfb719f4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArch1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_pair_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmResult1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_test_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUMBER_ROUNDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CrossEntropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArch2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_pair_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmResult2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_test_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUMBER_ROUNDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e6af4a4ec579>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f_gen_data, nb_epochs, mini_batch_size, learning_rate)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_gen_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_gen_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Baseline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m392\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes from 2 to 5 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "model1 = Arch1(generate_pair_sets)\n",
    "mResult1 = model1.train_and_test_rounds(NUMBER_ROUNDS, \"CrossEntropy\")\n",
    "\n",
    "model2 = Arch2(generate_pair_sets)\n",
    "mResult2 = model2.train_and_test_rounds(NUMBER_ROUNDS, \"Adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-freedom",
   "metadata": {},
   "source": [
    "## Plot results\n",
    "------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "        train_input, train_target, train_classes, \\\n",
    "            test_input, test_target, test_classes = self.generate_data(self.sets_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot only first model perf\n",
    "plot_model_result(mResult1, NUMBER_ROUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot only second model perf\n",
    "plot_model_result(mResult2, NUMBER_ROUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare perf\n",
    "plot_models_results_comparison([mResult1, mResult2], NUMBER_ROUNDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
